# LLM_Preprocessor üöÄ

> Production-ready document preprocessor that prepares mixed-format study material for LLM ingestion ‚Äî text extraction, high-quality OCR (Tesseract), format classification, memory-safe processing, and CPU-optimized parallelism.

---

## üî• Highlights

* ‚úÖ Converts mixed-format document corpus into GPT4All/LocalDocs-ready text
* ‚úÖ Detects scanned (image-only) files and performs OCR automatically
* ‚úÖ Two output zones: `Processed_Compatible/` (case **a & b**) and `Incompatible/` (case **c**)
* ‚úÖ Hash-based deduplication to skip previously processed files
* ‚úÖ Memory-safe page-by-page OCR with optional multithreading (configurable)
* ‚úÖ Minimal external dependencies ‚Äî Tesseract required; no heavy ML libs by default

---

## üìñ Table of Contents

* [Overview üìö](#overview-üìö)
* [How it works (algorithm) ‚öôÔ∏è](#how-it-works-algorithm-‚öôÔ∏è)
* [Quickstart üöÄ](#quickstart-üöÄ)
* [Installation üõ†Ô∏è](#installation-üõ†Ô∏è)
* [Usage ‚Äî run the script ‚ñ∂Ô∏è](#usage---run-the-script-Ô∏è)
* [Configuration üîß](#configuration-üîß)
* [Output structure & samples üóÇÔ∏è](#output-structure--samples-üóÇÔ∏è)
* [Architecture & processing flow üèóÔ∏è](#architecture--processing-flow-üèóÔ∏è)
* [Performance & tuning ‚ö°](#performance--tuning-‚ö°)
* [Troubleshooting ü©∫](#troubleshooting-ü©∫)
* [Contributing & License ‚ù§Ô∏è](#contributing--license-‚ù§Ô∏è)

---

## Overview üìö

LLM_Preprocessor is intended for people who have a large collection of learning material (PDFs, images, Word docs, Excel sheets, PPTs, EPUBs, etc.) and want to prepare a single, clean, text-first dataset to train or query local LLMs (e.g., GPT4All LocalDocs). It prioritizes quality of text extraction and OCR, robust memory control, and deterministic results across runs.

---

## How it works (algorithm) ‚öôÔ∏è

1. **Startup checks**: verify essential Python packages and static external binaries (Tesseract and Poppler if used).
2. **Discover files**: recursively scan `INPUT_DIR`.
3. For **each file**:
   * compute hash (skip if present in `filehash.json`)
   * attempt direct text extraction (PyMuPDF, python-docx, python-pptx, pandas, ebooklib, plain text)
   * if file is extension-compatible and text ‚â• threshold ‚Üí copy original to `Processed_Compatible` (case **a**)
   * if extension-compatible but text insufficient ‚Üí OCR (page-by-page) and write `.txt` to `Processed_Compatible` (case **b**)
   * if extension not supported ‚Üí copy to `Incompatible` for manual review (case **c**)
4. Record processed hashes to avoid re-processing; emit stats & logs.

---

## Quickstart üöÄ

**1. Clone repo**

```bash
git clone https://github.com/yourusername/LLM_Preprocessor.git
cd LLM_Preprocessor
```

**2. Place files**

* Drop your corpus into the configured `INPUT_DIR` (by default the script uses the static path you set in script).

**3. Install system dependencies (one-time):**

* Install **Tesseract OCR** (Windows: UB Mannheim build recommended) and note its `tesseract.exe` path.
* (Optional) If using Poppler-based PDF‚Üíimage conversion, install Poppler and note the `pdftoppm` path. The production script provided uses PyMuPDF for PDF rendering and does **not** require Poppler.

**4. Run the script (Spyder, VSCode, or terminal):**

```bash
python filePreparation_v2.py
```

---

## Installation üõ†Ô∏è

### Python packages

The script auto-checks and attempts to `pip install` the *lightweight* packages it needs:

* `pytesseract`, `Pillow`, `PyMuPDF` (fitz), `python-docx`, `python-pptx`, `pandas`, `tqdm`, `ebooklib`, `openpyxl`.

> **Important:** Do **not** install heavy ML packages (torch, torchvision, easyocr) unless you explicitly need handwriting OCR and understand the environment requirements.

### System binaries

* **Tesseract** ‚Äî required. Confirm via:

```bash
"C:\Program Files\Tesseract-OCR\tesseract.exe" --version
```

---

## Usage ‚Äî run the script ‚ñ∂Ô∏è

* Edit the static paths at the top of `filePreparation_v2.py`:

  * `INPUT_DIR` ‚Äî folder containing your raw files
  * `OUTPUT_DIR` ‚Äî where processed results go
  * `TESSERACT_CMD` ‚Äî path to `tesseract.exe`
  * `MAX_WORKERS` ‚Äî concurrency (default conservative)

* Execute:

```bash
python filePreparation_v2.py
```

You‚Äôll see live progress in the console. On completion the script prints a summary: total files, skipped (hash), case a (copied), case b (OCR -> txt), incompatible count, errors.

---

## Configuration üîß

Top-of-file configurable variables (edit in script):

```py
INPUT_DIR = r"..."
OUTPUT_DIR = r"..."
TESSERACT_CMD = r"..."
MAX_WORKERS = 3          # threads: increases CPU usage but watch RAM
MIN_TEXT_CHARS = 80      # threshold to decide OCR vs copy
```

**Tip:** Start with `MAX_WORKERS = 2` on low-RAM machines. Increase gradually.

---

## Output structure & samples üóÇÔ∏è

After a run, `OUTPUT_DIR` will contain:

```
knowledgeBase_prepared/
‚îú‚îÄ Processed_Compatible/         # Case (a) originals or .txt from OCR (case b)
‚îÇ  ‚îú‚îÄ *.txt                      # OCR/extracted text files
‚îÇ  ‚îî‚îÄ filehash.json              # hashes of processed files
‚îú‚îÄ Incompatible/                 # Case (c) unsupported or failed
‚îÇ  ‚îî‚îÄ <original files>
‚îî‚îÄ logs/
   ‚îú‚îÄ errors.log
   ‚îî‚îÄ processing_summary.json
```

**Sample outputs**

* `SomeDocument.pdf ‚Üí SomeDocument.txt` (if OCR used or text extracted)
* `Report.docx ‚Üí Report.docx` (copied as original if text present)
* `image_123.jpg ‚Üí image_123.txt` (image OCR output)

---

## Architecture & processing flow üèóÔ∏è

```
+-----------------+
| INPUT_DIR       |
| (mixed files)   |
+--------+--------+
         |
         v
+------------------------------+
| Discover & hash (skip dupes) |
+------------------------------+
         |
         v
+----------------------+    +---------------------+
| Text extraction pass |--->| text >= MIN_TEXT ?  |--Yes--> copy original -> Processed_Compatible
+----------------------+    +---------------------+
         |
         No
         v
+------------------------+
| OCR fallback (page-by-page)
+------------------------+
         |
         v
save OCR output .txt -> Processed_Compatible
         |
If failed -> move original -> Incompatible
```

---

## Performance & tuning ‚ö°

* **CPU**: The script uses a thread pool by default (`MAX_WORKERS`). Threads are chosen because heavy C-level libs (PyMuPDF, Tesseract) release the GIL during processing.
* **RAM**: PDF pages are rendered and OCR‚Äôd one-by-one ‚Äî images are deleted promptly and `gc.collect()` is used. If you still see MemoryErrors, reduce `MAX_WORKERS` to 1 or 2.
* **Throughput monitoring**: the script prints periodic throughput and ETA. Use these to decide whether to increase `MAX_WORKERS`.

---

## Troubleshooting ü©∫

### Q: `ModuleNotFoundError: No module named 'pdf2image'` or similar

* Run the script again ‚Äî it attempts to install missing lightweight packages.
* Or install manually with the interpreter Spyder uses:

```bash
python -m pip install pdf2image Pillow PyMuPDF pytesseract python-docx python-pptx pandas tqdm ebooklib openpyxl
```

### Q: Tesseract not found

* Ensure `TESSERACT_CMD` points to actual `tesseract.exe`
* Test in terminal:

```bash
"C:\Program Files\Tesseract-OCR\tesseract.exe" --version
```

### Q: MemoryError during OCR

* Reduce `MAX_WORKERS` in the script (start at 1‚Äì2)
* Close other heavy applications
* Consider splitting the job into smaller subfolders and run separately

### Q: Some `.doc` or `.ppt` files ended up in `Incompatible/`

* `.doc` (legacy Word) is unsupported by `python-docx` ‚Äî convert `.doc` ‚Üí `.docx` (Word or LibreOffice), or enable LibreOffice conversion logic (requires LibreOffice install).
* `.ppt` (older PPT) can be handled via conversion to `.pptx` (LibreOffice) or add an OLE parser.

### Optional: EasyOCR (handwriting)

* We **did not** enable EasyOCR by default because it requires `torch` and heavier dependencies which can cause environment issues.
* If you need handwriting support, install CPU PyTorch + easyocr in a clean environment:

```bash
pip install --upgrade pip
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip install easyocr
```

---

## Contact Me ‚ù§Ô∏è

* Built for you. You can DM me either here or on LinkedIn (https://www.linkedin.com/in/shubham-mehta-5141172b3/)
